{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f730d337",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3bc7a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8289dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train_correct.csv\")\n",
    "data = data[:4000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e9fdd63",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luis.castano.ortega/.local/lib/python3.9/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Hi Roy hope you are ok, Trans people are not g...</td>\n",
       "      <td>95e98db99c2</td>\n",
       "      <td>hi boy hope oka train people gay thing ram thr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>But fuckin' hell what even is biology</td>\n",
       "      <td>a87b8708e63</td>\n",
       "      <td>fucking hell biology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Whose the nice looking clergyman?</td>\n",
       "      <td>5b3cb03803f</td>\n",
       "      <td>nice look clergyman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>AIDS ARE IN YOUR WAY, SIN HAS CONSEQUENCES AND...</td>\n",
       "      <td>5b0bad2347e</td>\n",
       "      <td>aids way sin consequences bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>to learn</td>\n",
       "      <td>332048bd188</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>0</td>\n",
       "      <td>We dont have any apartments left. People now s...</td>\n",
       "      <td>f618ec39ebd</td>\n",
       "      <td>apartment leave people sleep outside sad turke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>1</td>\n",
       "      <td>Then stay put in Lebanon, Nisreena. Here in th...</td>\n",
       "      <td>7ea64e3633c</td>\n",
       "      <td>stay lebanon nisreena equality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>0</td>\n",
       "      <td>Wa'el Zaki</td>\n",
       "      <td>2f0c894f432</td>\n",
       "      <td>saki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>0</td>\n",
       "      <td>Slightly odd</td>\n",
       "      <td>9187c008564</td>\n",
       "      <td>slightly odd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>0</td>\n",
       "      <td>Well why don't you organise one Michael Cook</td>\n",
       "      <td>c28fa65ae6a</td>\n",
       "      <td>organize michael cook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text           id  \\\n",
       "0         0  Hi Roy hope you are ok, Trans people are not g...  95e98db99c2   \n",
       "1         0              But fuckin' hell what even is biology  a87b8708e63   \n",
       "2         0                  Whose the nice looking clergyman?  5b3cb03803f   \n",
       "3         1  AIDS ARE IN YOUR WAY, SIN HAS CONSEQUENCES AND...  5b0bad2347e   \n",
       "4         0                                           to learn  332048bd188   \n",
       "...     ...                                                ...          ...   \n",
       "3995      0  We dont have any apartments left. People now s...  f618ec39ebd   \n",
       "3996      1  Then stay put in Lebanon, Nisreena. Here in th...  7ea64e3633c   \n",
       "3997      0                                         Wa'el Zaki  2f0c894f432   \n",
       "3998      0                                       Slightly odd  9187c008564   \n",
       "3999      0       Well why don't you organise one Michael Cook  c28fa65ae6a   \n",
       "\n",
       "                                             clean_text  \n",
       "0     hi boy hope oka train people gay thing ram thr...  \n",
       "1                                  fucking hell biology  \n",
       "2                                   nice look clergyman  \n",
       "3                         aids way sin consequences bad  \n",
       "4                                                 learn  \n",
       "...                                                 ...  \n",
       "3995  apartment leave people sleep outside sad turke...  \n",
       "3996                     stay lebanon nisreena equality  \n",
       "3997                                               saki  \n",
       "3998                                       slightly odd  \n",
       "3999                              organize michael cook  \n",
       "\n",
       "[4000 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import classy_classification\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \n",
    " # Tokenización y lematización\n",
    "    doc = nlp(text)\n",
    "    tokens_lemmatized = [token.lemma_ for token in doc] \n",
    "    \n",
    "    # Eliminación de stopwords y caracteres especiales\n",
    "    clean_tokens = [token.lower() for token in tokens_lemmatized\n",
    "                    if not nlp.vocab[token].is_stop \n",
    "                    and not nlp.vocab[token].is_punct\n",
    "                    and token.isalpha \n",
    "                   ]\n",
    "    # Unir los tokens limpios en una cadena de texto nuevamente\n",
    "    clean_text = \" \".join(clean_tokens)\n",
    "    \n",
    "    # Expresión regular para encontrar URLs\n",
    "    #url_pattern = r'https?://\\S+|www\\.\\S+'\n",
    "    #clean_text = re.sub(url_pattern, 'URL', clean_text)\n",
    "    \n",
    "    return clean_text\n",
    "\n",
    "\n",
    "#División de datos\n",
    "\n",
    "data['clean_text'] = data['clean_text'].apply(preprocess_text)\n",
    "X = data['clean_text']\n",
    "y = data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test, = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b40e6f48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data_train = {}\n",
    "for i in range(len(X_train)):\n",
    "    etiqueta = y_train.iloc[i]\n",
    "    texto = X_train.iloc[i]\n",
    "    if etiqueta not in data_train:\n",
    "        data_train[etiqueta] = []\n",
    "    data_train[etiqueta].append(texto)\n",
    "\n",
    "# Mapeo de etiquetas\n",
    "label_mapping = { 0: \"no_hate\", 1: \"hate\"}\n",
    "# Convertir las etiquetas en el diccionario de datos\n",
    "data_train = {label_mapping[label]: texts for label, texts in data_train.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df395f72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "#import spacy_sentence_bert\n",
    "\n",
    "# paraphrase-multilingual-MiniLM-L12-v2 0.71\n",
    "\n",
    "\n",
    "# Cargar modelo SentenceTransformer\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# Agregar el componente de clasificación\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.add_pipe(\"classy_classification\", \n",
    "    config={\n",
    "        \"data\": data_train,\n",
    "        \"model\": model_name\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34092b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Realiza predicciones\n",
    "#predictions = [max(nlp(text)._.cats, key=nlp(text)._.cats.get) for text in X_test]\n",
    "\n",
    "# Realiza predicciones\n",
    "predictions = []\n",
    "\n",
    "for text in X_test:\n",
    "    cats = nlp(text)._.cats\n",
    "    if cats['hate'] - cats['no_hate'] > -0.0:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)\n",
    "\n",
    "\n",
    "# Convertir las predicciones de hate/no_hate a 1/0\n",
    "#predictions = [1 if cat == 'hate' else 0 for cat in predictions]\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, predictions)\n",
    "\n",
    "# Crear un mapa de calor de la matriz de confusión\n",
    "plt.figure(figsize=(3, 2))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='g', \n",
    "            xticklabels=['No ofensivo', 'Ofensivo'], \n",
    "            yticklabels=['No ofensivo', 'Ofensivo'])\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Etiqueta verdadera')\n",
    "plt.title('Matriz de Confusión')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84afa1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el conjunto de datos test\n",
    "test_data = pd.read_csv(\"test_nolabel_corr.csv\")\n",
    "\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a6f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar el preprocesamiento al texto\n",
    "test_data['clean_text'] = test_data['clean_text'].apply(preprocess_text)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2716e6e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Predicción\n",
    "#pred_new = [max(nlp(text)._.cats, key=nlp(text)._.cats.get) for text in test_data['clean_text']]\n",
    "\n",
    "# Convertir las predicciones de hate/no_hate a 1/0\n",
    "#pred_new = [1 if cat == 'hate' else 0 for cat in predictions]\n",
    "\n",
    "\n",
    "pred_new = []\n",
    "\n",
    "for text in test_data['clean_text']:\n",
    "    cats = nlp(text)._.cats\n",
    "    if cats['hate'] - cats['no_hate'] > -0.0:\n",
    "        pred_new.append(1)\n",
    "    else:\n",
    "        pred_new.append(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5330fdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame({'id': test_data[\"id\"], 'label': pred_new})\n",
    "\n",
    "predictions_df.to_csv(\"all-MiniLM_predictions.csv\", index=False, header=True)\n",
    "predictions_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
